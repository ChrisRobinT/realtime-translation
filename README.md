# ğŸŒ Real-Time Translation

> Break language barriers with AI-powered real-time voice translation

[![Live Demo](https://img.shields.io/badge/demo-live-success?style=for-the-badge)](https://realtime-translation-gules.vercel.app)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge)](LICENSE)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![Next.js](https://img.shields.io/badge/Next.js-16-black?style=for-the-badge&logo=next.js&logoColor=white)](https://nextjs.org/)

A WebRTC-based real-time audio translation application that enables seamless voice communication across language barriers. Connect with anyone, speak in your language, and let AI handle the translation instantly.

![App Demo](screenshots/demo-light.png)

## âœ¨ Features

- ğŸ™ï¸ **Real-Time P2P Voice** - Low-latency peer-to-peer communication via WebRTC
- ğŸŒ **Multi-Language Support** - Estonian, English, Spanish, German
- ğŸ¤– **AI-Powered Pipeline** - Whisper STT â†’ Azure Translator â†’ Azure Neural TTS
- ğŸ¨ **Beautiful UI** - Modern design with light/dark mode
- ğŸ“± **Responsive** - Works seamlessly on desktop and mobile
- ğŸ”’ **Secure** - Direct peer-to-peer connection, no audio stored on servers

## ğŸ¬ Demo

**Live Application:** [realtime-translation.vercel.app](https://realtime-translation-gules.vercel.app)

### Desktop Views

<table>
  <tr>
    <td><img src="screenshots/desktop-light.jpg" alt="Light Mode" /></td>
    <td><img src="screenshots/desktop-dark.png" alt="Dark Mode" /></td>
  </tr>
  <tr>
    <td align="center"><b>Light Mode</b></td>
    <td align="center"><b>Dark Mode</b></td>
  </tr>
</table>

### ğŸ“± Mobile Views

<table>
  <tr>
    <td align="center">
      <img src="screenshots/mobile-dark.png" width="300"/>
    </td>
    <td align="center">
      <img src="screenshots/mobile-light.png" width="300"/>
    </td>
  </tr>
  <tr>
    <td align="center"><b>Dark Mode</b></td>
    <td align="center"><b>Light Mode</b></td>
  </tr>
</table>

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+ 
- FFmpeg installed ([Download here](https://ffmpeg.org/download.html))
- API Keys:
  - [OpenAI API Key](https://platform.openai.com/api-keys)
  - [Azure Speech Services](https://azure.microsoft.com/en-us/services/cognitive-services/speech-services/)
  - [Azure Translator](https://azure.microsoft.com/en-us/services/cognitive-services/translator/)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/ChrisRobinT/realtime-translation.git
cd realtime-translation
```

2. **Setup Backend**
```bash
cd backend
npm install
cp .env.example .env
# Add your API keys to .env
node server.js
```

3. **Setup Frontend**
```bash
cd frontend
npm install
npm run dev
```

4. **Visit** `http://localhost:3000`

## ğŸ”‘ Environment Variables

Create `backend/.env` with:
```env
# OpenAI API
OPENAI_API_KEY=sk-your-openai-key

# Azure Speech Services
AZURE_SPEECH_KEY=your-azure-speech-key
AZURE_SPEECH_REGION=your-region

# Azure Translator
AZURE_TRANSLATE_KEY=your-azure-translator-key
AZURE_TRANSLATE_REGION=your-region

# Server Port (optional)
PORT=3001
```

## ğŸ—ï¸ Architecture

<img src="screenshots/realtime_architecture.jpeg" alt="Architecture" />

### How It Works

1. **Connect** - Two users join the same room ID
2. **P2P Voice** - Real-time audio streaming via WebRTC
3. **Record** - User presses button to record 5 seconds
4. **Transcribe** - Audio sent to OpenAI Whisper for speech-to-text
5. **Translate** - Text translated via Azure Translator
6. **Synthesize** - Translation converted to speech with Azure Neural TTS
7. **Play** - Translated audio plays automatically

## ğŸ› ï¸ Tech Stack

### Frontend
- **Framework:** Next.js 16 with TypeScript
- **Styling:** Tailwind CSS v4
- **Real-time:** Socket.io Client
- **WebRTC:** Simple-Peer
- **Icons:** Lucide React

### Backend
- **Runtime:** Node.js
- **Framework:** Express
- **Signaling:** Socket.io
- **STT:** OpenAI Whisper
- **Translation:** Azure Translator
- **TTS:** Azure Neural TTS
- **Audio Processing:** FFmpeg

### Infrastructure
- **Frontend Hosting:** Vercel
- **Backend Hosting:** Railway
- **WebRTC:** Direct P2P connection

## ğŸ“‚ Project Structure
```
realtime-translation/
â”œâ”€â”€ frontend/                # Next.js frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx        # Main app component
â”‚   â”‚   â”œâ”€â”€ layout.tsx      # Root layout
â”‚   â”‚   â””â”€â”€ globals.css     # Global styles
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ backend/                 # Node.js backend
â”‚   â”œâ”€â”€ server.js           # Express server + Socket.io
â”‚   â”œâ”€â”€ translationService.js  # AI pipeline
â”‚   â”œâ”€â”€ .env.example        # Environment template
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ README.md
```

## ğŸ¯ Usage

### For Users

1. **Open the app:** [realtime-translation.vercel.app](https://realtime-translation-gules.vercel.app)
2. **Create/Join Room:** Enter a room ID (e.g., "123")
3. **Share Room ID:** Give the same room ID to another person
4. **Connect:** Click "Connect to Room"
5. **Talk & Translate:**
   - Speak normally for real-time P2P voice
   - Click "Record & Translate" to translate speech
   - Hear the translation in your chosen language!

### Supported Languages

| Language | Code | Voice |
|----------|------|-------|
| ğŸ‡ªğŸ‡ª Estonian | `et` | Anu (Female) |
| ğŸ‡¬ğŸ‡§ English | `en` | Jenny (Female) |
| ğŸ‡ªğŸ‡¸ Spanish | `es` | Elvira (Female) |
| ğŸ‡©ğŸ‡ª German | `de` | Katja (Female) |

## ğŸš§ Roadmap

- [ ] Continuous translation mode (no button press)
- [ ] Support for 20+ languages
- [ ] Text chat alongside voice
- [ ] Recording history
- [ ] User authentication
- [ ] Room persistence
- [ ] Mobile app (React Native)
- [ ] Voice activity detection (VAD)
- [ ] Multi-party calls (3+ users)

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Guidelines

- Write clean, documented code
- Follow TypeScript best practices
- Test thoroughly before submitting PR
- Update README if adding features

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [OpenAI Whisper](https://openai.com/research/whisper) - Speech-to-text
- [Azure Cognitive Services](https://azure.microsoft.com/en-us/services/cognitive-services/) - Translation & TTS
- [Simple-Peer](https://github.com/feross/simple-peer) - WebRTC abstraction
- [Next.js](https://nextjs.org/) - React framework
- [Socket.io](https://socket.io/) - Real-time communication

## ğŸ‘¨â€ğŸ’» Author

**Chris-Robin Talts**

- GitHub: [@ChrisRobinT](https://github.com/ChrisRobinT)
- LinkedIn: [chrisrobintalts](https://linkedin.com/in/chrisrobintalts)
- Email: chrisrobin.talts@gmail.com

## ğŸ› Known Issues

- Translation works best with clear audio and minimal background noise
- 5-second recording limit (by design)
- Requires stable internet connection for translation API calls

## ğŸ’¡ FAQ

**Q: Is the audio stored anywhere?**  
A: No! Voice calls are peer-to-peer. Only the 5-second recordings for translation are temporarily sent to our server and immediately deleted.

**Q: Why do I need a room ID?**  
A: Room IDs ensure you connect to the right person. Think of it like a phone number.

**Q: Can I use this for professional translation?**  
A: While the AI is highly accurate, we recommend professional human translators for critical content.

**Q: Is it free?**  
A: The demo is free! However, running your own instance requires API keys which have costs.

---

<div align="center">

**Built with â¤ï¸ to break language barriers**

[â¬† Back to Top](#-real-time-translation)

</div>
